<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sample generated videos</title>
    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
</head>

<style type=""> .container { background-color: #EBEBEB; } </style>
<body>
    <div class="container">
        <h1 class="text-center my-5">Audio-driven Talking Face Generation by Overcoming Unintended Information Flow</h1>
        <h2 class="text-center my-5">Supplementary Videos</h2>

        <div style="padding-bottom:5%">
        <h3 class="">1. Ablation Study</h3>
        <p>This video contains output of different setups that were explained under <b>Section 5.3</b> in our paper. The scores were presented in <b>Table 2</b> in the paper.</p>
        <ol>
            <li><FONT COLOR="orange"><b>Setup A:</FONT></b> Base model with original/plain synchronization loss</li>
            <li><FONT COLOR="orange"><b>Setup D:</FONT></b> Base model with silent-lip generation model and pretrained SyncNet audio encoder</li>
            <li><FONT COLOR="orange"><b>Setup E:</FONT></b> Setup D with our proposed stabilized synchronization loss instead of original/plain synchronization loss</li>
            <li><FONT COLOR="orange"><b>Setup G:</FONT></b> Final setup. Setup E with adaptive triplet loss. This setup contains all our contributions.</li>
        </ol>
        </div>

        <div class="row justify-content-center", style="padding-bottom:5%">
            <div class="col-md-8">
                <div class="embed-responsive embed-responsive-16by9">
                    <video class="embed-responsive-item" controls>
                        <source src="ablation_study.mp4" type="video/mp4">
                    </video>
                </div>
            </div>
        </div>

        <div style="padding-bottom:5%">
        <h3 class="">2. Comparison with the Older Methods</h3>
        <p>Here, we compare our results with <a href>PC-AVS</a>, <a href>Wav2Lip</a> and <a href>EAMM</a> papers. We chose two videos from <a href>HDTF</a> dataset and randomly took a clip from each of them. In the end, we run the published models to generate the videos and combine in a single video by only putting faces to make the comparison easier.</p>

        <div class="row justify-content-center", style="padding-bottom:5%">
            <div class="col-md-8">
                <div class="embed-responsive embed-responsive-16by9">
                    <video class="embed-responsive-item" controls>
                        <source src="comparison_with_older_methods.mp4" type="video/mp4">
                    </video>
                </div>
            </div>
        </div>

        <h3 class="">3. Comparison with the Recent Methods</h3>
        <p>Here, we compare our method with the most recent and accurate methods; <a href>DINet (AAAI 2023)</a>, <a href>TalkLip (CVPR 2023)</a>, and <a href>VideoReTalking (SIGGRAPH 2022)</a>. Since the other recent methods in our paper (e.g., SyncTalkFace and LipFormer) have no public models, we were not be able to include them into this comparison. Please note that when we tried to generate video using FPS different than 25 with DINet and TalkLip models, the audio-visual synchronization was not obtained. Therefore, we had to keep the FPS as 25 (the authors shared like that) and generated below videos. On the other hand, with other models and our model, we kept the FPS the same with the original video which is 29.97. Therefore, DINet and TalkLip outputs look like they have different pose and head movemets. This is because of aforementioned FPS detail. We would like to clarify that there is <b>NO</b> generation error or <b>ANY</b> problem on these two models. However, if it is not possible do generate video with FPS value different than 25, then it is a significant drawback of these methods since there are lots of videos that have FPS value over than 30. In this case, those videos will be longer or suffer from lack of smoothness and information loss. </p>
        </div>

        <div class="row justify-content-center", style="padding-bottom:5%">
            <div class="col-md-8">
                <div class="embed-responsive embed-responsive-16by9">
                    <video class="embed-responsive-item" controls>
                        <source src="comparison1.mp4" type="video/mp4">
                    </video>
                </div>
            </div>
        </div>

        <div class="row justify-content-center", style="padding-bottom:5%">
            <div class="col-md-8">
                <div class="embed-responsive embed-responsive-16by9">
                    <video class="embed-responsive-item" controls>
                        <source src="comparison2.mp4" type="video/mp4">
                    </video>
                </div>
            </div>
        </div>

        <div class="row justify-content-center", style="padding-bottom:5%">
            <div class="col-md-8">
                <div class="embed-responsive embed-responsive-16by9">
                    <video class="embed-responsive-item" controls>
                        <source src="comparison3.mp4" type="video/mp4">
                    </video>
                </div>
            </div>
        </div>

        <h3 class="">4. Additional Videos Generated by Our Model</h3>
        <br>
        <h4 class="">4.1. Our full pipeline with face restoration</h4>

        <div class="row justify-content-center", style="padding-top:3%;padding-bottom:3%;">
            <div class="col-md-4">
                <div class="embed-responsive embed-responsive-16by9">
                    <video class="embed-responsive-item" controls>
                        <source src="video4.mp4" type="video/mp4">
                    </video>
                </div>
            </div>
            <div class="col-md-4">
                <div class="embed-responsive embed-responsive-16by9">
                    <video class="embed-responsive-item" controls>
                        <source src="video6.mp4" type="video/mp4">
                    </video>
                </div>
            </div>
            <div class="col-md-4">
                <div class="embed-responsive embed-responsive-16by9">
                    <video class="embed-responsive-item" controls>
                        <source src="video7.mp4" type="video/mp4">
                    </video>
                </div>
            </div>
        </div>
        <h4 class="">4.2. Our full pipelien without face restoration</h4>

        <div class="row justify-content-center", style="padding-top:3%;padding-bottom:3%;">
            <div class="col-md-4">
                <div class="embed-responsive embed-responsive-16by9">
                    <video class="embed-responsive-item" controls>
                        <source src="video8.mp4" type="video/mp4">
                    </video>
                </div>
            </div>

            <div class="col-md-4">
                <div class="embed-responsive embed-responsive-16by9">
                    <video class="embed-responsive-item" controls>
                        <source src="video10.mp4" type="video/mp4">
                    </video>
                </div>
            </div>

            <div class="col-md-4">
                <div class="embed-responsive embed-responsive-16by9">
                    <video class="embed-responsive-item" controls>
                        <source src="video14.mp4" type="video/mp4">
                    </video>
                </div>
            </div>
        </div>

        <h4 class="">4.3. Different speakers with the same audio</h4>
        <p>We use 6 different speakers and use 5 different audios consecutively to generate talking faces.</p>

        <div class="row justify-content-center", style="padding-bottom:5%">
            <div class="col-md-8">
                <div class="embed-responsive embed-responsive-16by9">
                    <video class="embed-responsive-item" controls>
                        <source src="demo2.mp4" type="video/mp4">
                    </video>
                </div>
            </div>
        </div>

        <h4 class="">4.4 Videos for rebuttal</h4>

        <p>We use 5 different videos with a single audio to generate talking faces. The videos are sample videos presented by DINet. For the face enhancement, we used VQFR as we proposed in our paper.</p>

        <div class="row justify-content-center", style="padding-bottom:5%">
            <div class="col-md-8">
                <div class="embed-responsive embed-responsive-16by9">
                    <video class="embed-responsive-item" controls>
                        <source src="final_VQFR_videos1.mp4" type="video/mp4">
                    </video>
                </div>
            </div>
        </div>
        
        <p>We use 5 different videos with a single audio to generate talking faces. The videos are sample videos presented by DINet. For the face enhancement, instead of using VQFR that we proposed in our paper, we employed GFPGAN in order to show that the illumination inconsistency in our final videos were caused by VQFR face enhancement method.</p>

        <div class="row justify-content-center", style="padding-bottom:5%">
            <div class="col-md-8">
                <div class="embed-responsive embed-responsive-16by9">
                    <video class="embed-responsive-item" controls>
                        <source src="final_GFPGAN_videos.mp4" type="video/mp4">
                    </video>
                </div>
            </div>
        </div>

        

    </div>

    <!-- Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.9.3/dist/umd/popper.min.js"
            integrity="sha384-0jtkM0gDJxkPQfE+yoK1Rv7I9zj8XV7lQdYUsRvhrNAdxNmmKq3eiqkBM12nVzJa"
            crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>
</body>
</html>
